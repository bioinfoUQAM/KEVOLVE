{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier(n_estimators=1000, criterion='gini', max_depth=None,  bootstrap=True, n_jobs=-1, random_state=0)\n",
    "# SVC(C=1.0, kernel='linear', tol=0.001, cache_size=2000, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False)\n",
    "# NearestNeighbors(n_neighbors=10, radius=1.0, algorithm='auto', leaf_size=30, metric='minkowski', p=2, metric_params=None, n_jobs=None)\n",
    "# MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import exrex\n",
    "import numpy\n",
    "import Bio.SeqIO\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert degenerative k-mers into a list of k-mers \n",
    "def convert_degenerative_k_mers(k_mer):\n",
    "\tk_mers = []\n",
    "\ttemp_k_mer = \"\"\n",
    "\t\n",
    "\tfor n in range(len(k_mer)): \n",
    "\t\tif k_mer[n] == \"A\": temp_k_mer = temp_k_mer + \"[A]\"\n",
    "\t\tif k_mer[n] == \"C\": temp_k_mer = temp_k_mer + \"[C]\"\n",
    "\t\tif k_mer[n] == \"G\": temp_k_mer = temp_k_mer + \"[G]\"\n",
    "\t\tif k_mer[n] == \"T\": temp_k_mer = temp_k_mer + \"[T]\"\n",
    "\t\tif k_mer[n] == \"N\": temp_k_mer = temp_k_mer + \"[ACGT]\"\n",
    "\t\tif k_mer[n] == \"X\": temp_k_mer = temp_k_mer + \"[ACGT]\"\n",
    "\t\tif k_mer[n] == \"V\": temp_k_mer = temp_k_mer + \"[^ACG]\"\n",
    "\t\tif k_mer[n] == \"H\": temp_k_mer = temp_k_mer + \"[^ACT]\"\n",
    "\t\tif k_mer[n] == \"D\": temp_k_mer = temp_k_mer + \"[^AGT]\"\n",
    "\t\tif k_mer[n] == \"B\": temp_k_mer = temp_k_mer + \"[^CGT]\"\n",
    "\t\tif k_mer[n] == \"M\": temp_k_mer = temp_k_mer + \"[AC]\"\n",
    "\t\tif k_mer[n] == \"W\": temp_k_mer = temp_k_mer + \"[AT]\"\n",
    "\t\tif k_mer[n] == \"R\": temp_k_mer = temp_k_mer + \"[AG]\"\n",
    "\t\tif k_mer[n] == \"K\": temp_k_mer = temp_k_mer + \"[GT]\"\n",
    "\t\tif k_mer[n] == \"S\": temp_k_mer = temp_k_mer + \"[CG]\"\n",
    "\t\tif k_mer[n] == \"Y\": temp_k_mer = temp_k_mer + \"[CT]\"\n",
    "\n",
    "\tfor i in exrex.generate(temp_k_mer): \n",
    "\t\tk_mers.append(i)\n",
    "\treturn k_mers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load test data from a fasta file\n",
    "def loadDataTrain(file_path):\n",
    "\t# Initialize the data matrix\n",
    "\tD = []\n",
    "\t# Iterate through the fasta file\n",
    "\tfor record in Bio.SeqIO.parse(file_path, \"fasta\"):\n",
    "\t\t# If there is a class label, save id, sequence and class label in the data list\n",
    "\t\ttry: \n",
    "\t\t\tindexes = [i for i, c in enumerate(record.description) if c == \"|\"]\n",
    "\t\t\tD.append([record.description, str(record.seq.upper()).replace('N',''), record.description[indexes[len(indexes)-1] +1 :]])\n",
    "\t\t# If there is a no class label, save id and sequence in the data list\n",
    "\t\texcept: D.append([record.descrition, str(record.seq.upper())])\n",
    "\t# Return the data matrix\n",
    "\treturn D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load test data from a fasta file\n",
    "def loadDataTest(file_path, D_train):\n",
    "\t# Load train data to remove it from test data\n",
    "\tid = [d[0] for d in D_train]\n",
    "\tD_train.clear()\n",
    "\t# Initialize the data matrix\n",
    "\tD = []\n",
    "\t# Iterate through the fasta file\n",
    "\tfor record in Bio.SeqIO.parse(file_path, \"fasta\"):\n",
    "\t\t# If there is a class label, save id, sequence and class label in the data list\n",
    "\t\ttry: \n",
    "\t\t\t# Get index of last separator\n",
    "\t\t\tindexes = [i for i, c in enumerate(record.description) if c == \"|\"]\n",
    "\t\t\t# Save id, sequence and class label\n",
    "\t\t\tif record.description not in id:\n",
    "\t\t\t\tD.append([record.description, str(record.seq.upper()), record.description[indexes[len(indexes)-1] +1 :]])\n",
    "\t\t# If there is a no class label, save id and sequence in the data list\n",
    "\t\texcept: D.append([record.descrition, str(record.seq.upper())])\n",
    "\t# Return the data matrix\n",
    "\treturn D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the occurence vector of sequence\n",
    "def computeSequenceVector(d, K, k):\n",
    "\t# Generate an empty dictionary\n",
    "\tx = {}\n",
    "\t# Initialize the dictionary with targets as keys and 0 as value\n",
    "\tx = x.fromkeys(K.keys(), 0)\n",
    "\t# Go through the sequence \n",
    "\tfor i in range(0, len(d[1]) - k + 1, 1):\n",
    "\t\t# Try to increment the current k-mer value by 1\n",
    "\t\ttry: x[d[1][i:i + k]] = x[d[1][i:i + k]] + 1\n",
    "\t\t# Pass if the k-mers does not exist\n",
    "\t\texcept: pass\n",
    "\t# Return the vector and associated target\n",
    "\treturn [list(x.values()), d[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate the samples matrix (X) and the target values (y)\n",
    "def generateSamplesTargets(D, K, k):\n",
    "\t# Samples matrix\n",
    "\tX = []\n",
    "\t# Target values\n",
    "\ty = []\n",
    "\t# Iterate through the data\n",
    "\tdata = Parallel(n_jobs = -1)(delayed(computeSequenceVector)(d, K, k) for d in D)\n",
    "\t# Add to the matrices\n",
    "\tfor d in data: \n",
    "\t\tX.append(d[0])\n",
    "\t\ty.append(d[1])\n",
    "\n",
    "\t# Convert to numpy array format\n",
    "\tX = numpy.asarray(X)\n",
    "\ty = numpy.asarray(y)\n",
    "\t# Return the samples matrix (X) and the target values (y)\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lebat\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) precision 0.7898205778876003 recall 0.9019853461407499 f1_score 0.8204740848174261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lebat\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2) precision 0.828673606333948 recall 0.8558693387206349 f1_score 0.8385538633462819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lebat\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3) precision 0.9669644563636999 recall 0.9960388816748251 f1_score 0.9798721547148354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lebat\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4) precision 0.7841080581574988 recall 0.8226172381758203 f1_score 0.7685715221216919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lebat\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5) precision 0.8547299574214515 recall 0.8794237308161076 f1_score 0.857900468153279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lebat\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6) precision 0.9033309499846643 recall 0.9011288907088998 f1_score 0.8737117829945221\n",
      "7) precision 0.9298729862329278 recall 0.9951249940871699 f1_score 0.9554894886471793\n",
      "8) precision 0.8254473243182296 recall 0.9911882327339956 f1_score 0.8620456732088778\n",
      "9) precision 0.8778656912005556 recall 0.9913002233044818 f1_score 0.9078749907029957\n",
      "10) precision 0.7611451454082478 recall 0.8583479369918813 f1_score 0.7448561908306359\n",
      "11) precision 0.6504580332566288 recall 0.6496953704812215 f1_score 0.6275998574661082\n",
      "12) precision 0.8978286554972381 recall 0.9308746977515243 f1_score 0.8715902732188894\n",
      "13) precision 0.8585847767976205 recall 0.9625945603544004 f1_score 0.8596277598176257\n",
      "14) precision 0.9750415149354271 recall 0.9961893453820647 f1_score 0.9846627116545692\n",
      "15) precision 0.9763768681024849 recall 0.997240452240576 f1_score 0.9855078815529236\n",
      "16) precision 0.9216416576166602 recall 0.9143924012008876 f1_score 0.9166027572538262\n",
      "17) precision 0.8842265645973006 recall 0.9752747282404602 f1_score 0.8855391486411239\n",
      "18) precision 0.7896040850515004 recall 0.8247390985047064 f1_score 0.7858790374161767\n",
      "19) precision 0.7866893386009547 recall 0.8652669965173014 f1_score 0.7776979515425482\n",
      "20) precision 0.8798819185354538 recall 0.8962982919124702 f1_score 0.8131154670480809\n",
      "21) precision 0.9097548435285479 recall 0.9925645455103522 f1_score 0.9205134347233667\n",
      "22) precision 0.9395702623535064 recall 0.9670992758789172 f1_score 0.9462586804448179\n",
      "23) precision 0.7746164034667322 recall 0.8094631249596725 f1_score 0.7720889063285028\n",
      "24) precision 0.8798053424427701 recall 0.9917348223321196 f1_score 0.9003660444835975\n",
      "25) precision 0.8644510796403505 recall 0.9078840564424828 f1_score 0.8759432893216956\n",
      "26) precision 0.8675506087992622 recall 0.918084006288623 f1_score 0.8868111233243322\n",
      "27) precision 0.828295967225601 recall 0.9140576046482941 f1_score 0.849871891181899\n",
      "28) precision 0.8777218607952945 recall 0.9119036024886154 f1_score 0.8863864415831573\n",
      "29) precision 0.8414909506365775 recall 0.9095802002454638 f1_score 0.7894443341653449\n",
      "30) precision 0.6203895901842439 recall 0.6455242815621959 f1_score 0.5984698616452\n",
      "31) precision 0.8027843783017641 recall 0.837965275913702 f1_score 0.747781189985137\n",
      "32) precision 0.9624851766228579 recall 0.9968830754724047 f1_score 0.9781779845124831\n",
      "33) precision 0.8280610631151382 recall 0.9083598788096238 f1_score 0.8007263131963581\n",
      "34) precision 0.8693016919777399 recall 0.9960978501158919 f1_score 0.9064686434281614\n",
      "35) precision 0.8633075873708069 recall 0.9450138634039076 f1_score 0.866888043458335\n",
      "36) precision 0.8259082534175952 recall 0.9612177113665688 f1_score 0.8342395124339621\n",
      "37) precision 0.8973934608614922 recall 0.991082809738371 f1_score 0.9104748282668943\n",
      "38) precision 0.8197616339353804 recall 0.9021484025035867 f1_score 0.8415213018070858\n",
      "39) precision 0.8696832933922864 recall 0.9013943742038636 f1_score 0.8806651447537248\n",
      "40) precision 0.9722444647428798 recall 0.9959354836382985 f1_score 0.9829479444474183\n",
      "41) precision 0.8848968708009073 recall 0.9057417241393629 f1_score 0.8923094263522241\n",
      "42) precision 0.8770451619235878 recall 0.9824454220525538 f1_score 0.8927434952897138\n",
      "43) precision 0.9094036786702885 recall 0.9941709017667131 f1_score 0.9326026082740413\n",
      "44) precision 0.8653061508733402 recall 0.9027462080937465 f1_score 0.8819842172116082\n",
      "45) precision 0.8314971218053685 recall 0.8809601185028406 f1_score 0.846722010348096\n",
      "46) precision 0.9068813099584554 recall 0.9962381829141442 f1_score 0.9336045409915343\n",
      "47) precision 0.9442053435709088 recall 0.9941898460629354 f1_score 0.9656856913091374\n",
      "48) precision 0.8974196065873518 recall 0.9107022283634881 f1_score 0.8996210647684253\n",
      "49) precision 0.8989690904231304 recall 0.9564832355372219 f1_score 0.9099921903731026\n",
      "50) precision 0.8882914200964814 recall 0.9944719169182324 f1_score 0.9233616431708794\n",
      "51) precision 0.8538399282586069 recall 0.908696737413097 f1_score 0.8082596512995679\n",
      "52) precision 0.857407368125585 recall 0.9034234183075689 f1_score 0.8365727342068732\n",
      "53) precision 0.9783482224857869 recall 0.995721624023642 f1_score 0.9866450920917046\n",
      "54) precision 0.789131004208062 recall 0.8170553591156423 f1_score 0.7211126492134856\n",
      "55) precision 0.8808691684320721 recall 0.991834430814208 f1_score 0.9015572013050864\n",
      "56) precision 0.706472718434784 recall 0.8666401966282 f1_score 0.6257026106861076\n",
      "57) precision 0.8676716413011517 recall 0.9062233690173039 f1_score 0.8813374171458644\n",
      "58) precision 0.9047837574851968 recall 0.9957691507199904 f1_score 0.9194357943745718\n",
      "59) precision 0.7540775699976299 recall 0.8250347622892076 f1_score 0.7387325232976486\n",
      "60) precision 0.9635383855383928 recall 0.9849551124697747 f1_score 0.97323066107939\n",
      "61) precision 0.9257483344296908 recall 0.9957130920173907 f1_score 0.9480202732752933\n",
      "62) precision 0.9524632368143804 recall 0.9974920425392828 f1_score 0.971759894120178\n",
      "63) precision 0.7552076984069525 recall 0.8847153614536092 f1_score 0.6811181402594828\n",
      "64) precision 0.9235726222222379 recall 0.9961890789273673 f1_score 0.9482597649936236\n",
      "65) precision 0.9563433682669968 recall 0.9962072461242413 f1_score 0.9748709605174302\n",
      "66) precision 0.8668905724117323 recall 0.9643755989237685 f1_score 0.8676023768114943\n",
      "67) precision 0.8162740488207028 recall 0.8225892969615168 f1_score 0.7828283021998382\n",
      "68) precision 0.8973121121521637 recall 0.943719065894182 f1_score 0.8687113332353633\n",
      "69) precision 0.8823434632055454 recall 0.9911073782410462 f1_score 0.9038847548016455\n",
      "70) precision 0.8754405582724754 recall 0.972046308318163 f1_score 0.9106199944611486\n",
      "71) precision 0.9116038113375421 recall 0.9904049344593634 f1_score 0.9295531832669134\n",
      "72) precision 0.865437268870634 recall 0.993613058360223 f1_score 0.9039782669450593\n",
      "73) precision 0.8840986756203923 recall 0.9047656171536508 f1_score 0.8939289480886383\n",
      "74) precision 0.8709304373235728 recall 0.9017660205456247 f1_score 0.8830475708755647\n",
      "75) precision 0.980733787621247 recall 0.9968123225868144 f1_score 0.9884036409424862\n",
      "76) precision 0.7525793691721687 recall 0.8065943313435688 f1_score 0.7679707356377536\n",
      "77) precision 0.9326640346556339 recall 0.993770230546082 f1_score 0.9492635801142791\n",
      "78) precision 0.9071025022597144 recall 0.9922521232814882 f1_score 0.9367413601012551\n",
      "79) precision 0.893492806425581 recall 0.9262942926485636 f1_score 0.8458783362005272\n",
      "80) precision 0.9027533849446288 recall 0.984029382621159 f1_score 0.9143073216879201\n",
      "81) precision 0.8904833896046066 recall 0.8929763892681668 f1_score 0.8736231858279982\n",
      "82) precision 0.908846095622892 recall 0.9963943317462327 f1_score 0.9307668455183034\n",
      "83) precision 0.9033740853144552 recall 0.9662174015287673 f1_score 0.8971648249575912\n",
      "84) precision 0.9032385087857262 recall 0.9918366265286371 f1_score 0.9236609623514311\n",
      "85) precision 0.8974126971823481 recall 0.9921339685416534 f1_score 0.9228642699737598\n",
      "86) precision 0.8775566032651285 recall 0.9889332815706254 f1_score 0.8969343457990184\n",
      "87) precision 0.9196230086285387 recall 0.9279549704689674 f1_score 0.9235096603872597\n",
      "88) precision 0.876723837266584 recall 0.9747898477871579 f1_score 0.881648515250899\n",
      "89) precision 0.8634444649794121 recall 0.9058699140174001 f1_score 0.8821722020960594\n",
      "90) precision 0.8735789665100617 recall 0.9960040101201342 f1_score 0.9147983757528932\n",
      "91) precision 0.9659451055956432 recall 0.9941291688413241 f1_score 0.9790874998645849\n",
      "92) precision 0.9748290490368255 recall 0.9974509468447638 f1_score 0.9856454950507143\n",
      "93) precision 0.9209508154791912 recall 0.9937477444545463 f1_score 0.9420551256254301\n",
      "94) precision 0.7954375625431004 recall 0.8229928334217462 f1_score 0.7977502370581016\n",
      "95) precision 0.8267150701994119 recall 0.8562801132359278 f1_score 0.8201458944278033\n",
      "96) precision 0.9281165530407437 recall 0.9959559207118227 f1_score 0.9468000762048593\n",
      "97) precision 0.9307881023666844 recall 0.9967607642174295 f1_score 0.9532135635223401\n",
      "98) precision 0.9277411694966151 recall 0.995321686440701 f1_score 0.9462907757567063\n",
      "99) precision 0.8796500937667018 recall 0.9928443196373321 f1_score 0.9002386622367379\n",
      "100) precision 0.8812046875375353 recall 0.9897324032031511 f1_score 0.8975872318870823\n"
     ]
    }
   ],
   "source": [
    "# Compute and save performance metrics for STREME\n",
    "data = {}\n",
    "\n",
    "# Define the list of variants\n",
    "variants = [\"Alpha\", \"Beta\", \"Delta\", \"Epsilon\", \"Eta\", \"Gamma\", \"Iota\", \"Kappa\", \"Lambda\", \"Omicron\"]\n",
    "# Iterate throught prediction files\n",
    "for n in range(1, 101): \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    k_mers = []\n",
    "    for variant in variants:\n",
    "        with open(\"MEME_OOPS/\" + str(n) + \"/\" + variant +  \"/meme.txt\") as file:\n",
    "            for line in file: \n",
    "                if line.strip().count(\"MOTIF\") and line.strip().count(\"width =   9\"): \n",
    "                    line = line.strip()\n",
    "                    start = 6\n",
    "                    end = start + 9\n",
    "                    k_mer =  line[start:end]\n",
    "                    if bool(re.match('^[ACGT]+$', k_mer)) == True: \n",
    "                       k_mers.append(k_mer)\n",
    "                    else: \n",
    "                        temp_k_mers = convert_degenerative_k_mers(k_mer)\n",
    "                        for temp_k_mer in temp_k_mers: \n",
    "                            k_mers.append(temp_k_mer)\n",
    "    k_mers = set(k_mers)\n",
    "\n",
    "    K = dict.fromkeys(k_mers, 0)\n",
    "    D_train = loadDataTrain(\"data/SARS-CoV-2_train_\" + str(n) + \".fasta\")\n",
    "    X_train, y_train = generateSamplesTargets(D_train, K , 9)\n",
    "\n",
    "    D_test = loadDataTest(\"data/SARS-CoV-2.fasta\", D_train)\n",
    "    X_test, y_test = generateSamplesTargets(D_test, K , 9)\n",
    "\n",
    "    model = SVC(kernel = 'linear', C = 1, cache_size = 1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Compute the performance metrics\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    print(str(n) +\") precision\", precision, \"recall\", recall, \"f1_score\", f1)\n",
    "\n",
    "    # Save the predictions\n",
    "    file = open(\"MEME_OOPS/\" + str(n) + \"/prediction.csv\", \"w\")\n",
    "    file.write(\"id,y_pred\\n\")\n",
    "    for i, y in enumerate(y_pred): file.write(D_test[i][0] + \",\" + y + \"\\n\")\n",
    "    file.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1d675c2f4f889dd09212fec10ba36e21d8557edcac2b728432b54c97897b7bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
